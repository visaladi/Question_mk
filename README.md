# Question_mk

:

##ğŸ“˜ PDF â†’ Questions Generator (MCQ & Essay)

This project converts any uploaded PDF document into automatically generated Multiple-Choice Questions (MCQ) or Essay questions using a Large Language Model (LLM).
Itâ€™s built with FastAPI (backend), Gemini API (LLM), and a simple HTML/Tailwind/HTMX frontend for interaction.

ğŸš€ Features

ğŸ“‚ Upload a PDF and instantly generate MCQs or Essay questions.

ğŸ¯ Choose difficulty level: easy, medium, hard.

âš™ï¸ Configurable backend/model (default: Google Gemini 2.0 Flash).

ğŸ§  Supports semantic chunking of PDFs & context retrieval.

âœ¨ Reranking support with cross-encoder (optional).

ğŸ’¾ Questions auto-saved as JSON in outputs/.

ğŸ–¥ï¸ Clean web UI (HTMX + Tailwind).

##ğŸ› ï¸ Tech Stack

Backend: FastAPI

Frontend: TailwindCSS + HTMX

LLM: Google Gemini API

PDF Parsing: PyMuPDF

Embeddings & Reranking: sentence-transformers / cross-encoders

##ğŸ“‚ Project Structure
Question_mk/
â”‚â”€â”€ config/             # Config (backend, model, API key)
â”‚   â””â”€â”€ config.py
â”‚â”€â”€ core/               # Core logic
â”‚   â”œâ”€â”€ pdf_utils.py    # PDF parsing + chunking
â”‚   â”œâ”€â”€ embed_store.py  # Embedding store
â”‚   â”œâ”€â”€ llm_client.py   # LLM client (Gemini / HF / Ollama)
â”‚   â”œâ”€â”€ prompts.py      # Prompt templates
â”‚   â””â”€â”€ schemas.py      # Pydantic models
â”‚â”€â”€ extras/             # Optional extras (NER, reranking)
â”‚â”€â”€ front_end/          # UI
â”‚   â”œâ”€â”€ static/         # JS, CSS
â”‚   â”‚   â””â”€â”€ app.js
â”‚   â””â”€â”€ templates/      # HTML (index.html)
â”‚â”€â”€ outputs/            # Auto-saved generated questions
â”‚â”€â”€ main.py             # FastAPI entrypoint
â”‚â”€â”€ requirements.txt
â””â”€â”€ README.md

##âš™ï¸ Setup
1ï¸âƒ£ Clone the repo
git clone https://github.com/<your-username>/pdf-question-generator.git
cd pdf-question-generator

2ï¸âƒ£ Create a virtual environment
python -m venv .venv
source .venv/bin/activate      # Linux/Mac
.venv\Scripts\activate         # Windows (PowerShell)

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Configure your API key

Edit config/config.py and add your Gemini API key:

@dataclass
class AppConfig:
    LLM_BACKEND: str = "gemini"
    LLM_MODEL: str   = "gemini-2.0-flash"
    GEMINI_API_KEY: str = "YOUR_GEMINI_KEY"
    USE_RERANK: bool = False
    HOST: str = "127.0.0.2"
    PORT: int = 8000

###â–¶ï¸ Run the App
python main.py


###App will be served at:

Backend API: http://127.0.0.2:8000

Frontend UI: http://127.0.0.2:8000/

Swagger docs: http://127.0.0.2:8000/docs

##ğŸ’¡ Usage

Open http://127.0.0.2:8000/

Upload a PDF file.

Select:

Question type: MCQ or Essay

Difficulty: easy / medium / hard

Count: number of questions

Topic (optional): narrow focus

Click Generate.

âœ… Questions appear on the page:

MCQs â†’ interactive quiz style

Essays â†’ with rubric & target keywords

ğŸ’¾ Download results as JSON (saved automatically in outputs/).



##ğŸ”® Roadmap

 Add CSV export for questions.

 Support more LLMs (OpenAI, Anthropic, Mistral).

 Add option to shuffle MCQ choices.

 Authentication + multi-user support.

##ğŸ¤ Contributing

Pull requests are welcome! For major changes, open an issue first to discuss what youâ€™d like to add.

###ğŸ“œ License

MIT License Â© 2025
